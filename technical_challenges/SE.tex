\newpage
\section{Simulation Evaluation Test}

\subsection{Purpose and Focus of the Test}

The purpose of this test is to provide the RoboCup @Work League with new capabilities. These capabilities are the option to do scientific evaluation regarding stochastic behaviour and scalability analysis. This provide the competing teams with the option of using their experimental results in scientific papers and provide a stronger link to the scientific robotic communities.

Another aspect is the option to add integration tests and continuous integration to the workflow of the teams to provide better management of software versions. Additionally, this provides the team members with the capabilities to learn state-of-the-art software development techniques.

Finally, a simulation adds the option for new teams to start with a virtual robot excluding the typical hardware problems associated with real robots. This eases the entry into the league and paves the way for a larger growth of the league in regard to participating teams in the future. 

\subsection{Scenario Environment}

The scenario for this test is to enable teams using a (partial) simulation to show these to the league. Finally, the league may be able to chose a default simulation environment to provide support for this environment in the future. 

Consequently, the simulation of the team competing in this challenge needs to fulfill some requirements:

\begin{description}
  \item[Free to be used:] The simulation software needs to be usable by competing teams free of charge. The software does not need to be open source.
  \item[Open-Source API:] The interface of the simulation needs to be open source. Especially, the implementation of the robot specific functions and behaviours, like executing movement commandos and outputting laser scanner data etc.\ needs to be implemented in an way that allows for easy modification of interested teams.
  \item[Official Models:] The simulated arena environment need to contain the 3D-Model of the official repository of the @Work League \url{https://github.com/robocup-at-work/models}. Additionally, the tasks to be executed need to be generated by the official Referee Box, see Section~\ref{sec:refbox}
\end{description}

  Within the simulation environment one of the tasks specified in Section~\ref{sec:tests} needs to be executed.

\subsection{Task}

The task of this challenge is to show the execution of one of the tasks defined in Section~\ref{sec:tests} in the virtual environment. However, this task is not graded regarding the normal scoring scheme. The evaluation of this task is based on the behaviour of the simulation itself. Relevant aspects that are considered in the scoring are the precision and speed of the simulation. To this end, the teams shall provide stochastic data on the precision of multiple runs of their simulation  as well as the speed of the simulation expressed as a real-time-factor (Quotient between time passed in the simulation and time passed in the real world). Additionally, the teams need to indicate the API of their simulation as well as the sued simulation software and its license. The task execution may either be shown in a video or live. 

\subsection{Rules}

\begin{itemize}
  \item Virtual representation based on the object and table definitions from \url{https://github.com/robocup-at-work/models}
  \item Virtual representation of the teams robot
  \item Free to use (for robotic teams) simulation software / environment
  \item Execution of a task as specified in Section~\ref{sec:tests}
  \item Start of task by Referee Box see Section~\ref{sec:refbox}
  \item Task execution as video or live
  \item Indication of precision in form of reproduction accuracy (execute multiple times and compare results)
  \item Indication of simulation speed based on real-time factor (Quotient between virtual clock speed and real world time)
\end{itemize}

\subsection{Scoring}

Referees grade task execution and simulation based on the following criteria:
\begin{itemize}
  \item Up to 100 Points for Ease of Use
  \item Up to 100 Points for Visualization
  \item Up to 200 Points for Precision
  \item Up to 200 Points for Speed
  \item Up to 300 Points for Simulation Capabilities
\end{itemize}


